{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f158476-116b-48af-803c-2be46b0eac9a",
   "metadata": {},
   "source": [
    "## Notebook: Extracting Default Image and Metadata Features\n",
    "\n",
    "This notebook builds on the dataset demo you provided. It extracts two features per instance:\n",
    "\n",
    "- **Image Feature**: Computes the average color (RGB) of the image.\n",
    "- **Metadata Feature**: Encodes the primary type (Type1) as a numeric value.\n",
    "\n",
    "Both features are saved to dedicated directories for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2d04d3-0ec9-489c-ac5a-afa01614194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and path configurations are set up:\n",
      " - Notebook Dir: /app/notebooks\n",
      " - Repository Root: /app\n",
      " - Dataset Path: /app/data\n",
      " - Image Dir: /app/data/images\n",
      " - Metadata Path: /app/data/metadata/images.json\n",
      " - Feature Dir: /app/data/features\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "\n",
    "# --- Path Definitions ---\n",
    "# Base directories as per your Docker mount configuration\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "DATASET_PATH = REPO_ROOT / \"data\"\n",
    "\n",
    "# Image and metadata directories\n",
    "IMAGE_DIR = DATASET_PATH / \"images\"\n",
    "METADATA_PATH = DATASET_PATH / \"metadata\" / \"images.json\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METADATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Directories for storing extracted features\n",
    "FEATURE_DIR = DATASET_PATH / \"features\"\n",
    "\n",
    "# Create feature directories if they don't exist\n",
    "FEATURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Imports and path configurations are set up:\")\n",
    "print(f\" - Notebook Dir: {NOTEBOOK_DIR}\")\n",
    "print(f\" - Repository Root: {REPO_ROOT}\")\n",
    "print(f\" - Dataset Path: {DATASET_PATH}\")\n",
    "print(f\" - Image Dir: {IMAGE_DIR}\")\n",
    "print(f\" - Metadata Path: {METADATA_PATH}\")\n",
    "print(f\" - Feature Dir: {FEATURE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a16b6-1fd3-439a-bb74-8bd8713a9af2",
   "metadata": {},
   "source": [
    "### Define Default Feature Extraction Functions\n",
    "\n",
    "**Image Feature Extraction:** We open each image using PIL and compute the average pixel values across all pixels.\n",
    "\n",
    "**Metadata Feature Extraction:** We extract the primary type (`Type1`) from the metadata and encode it using a simple mapping.\n",
    "\n",
    "Feel free to modify these functions to compute more complex features later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6009a43-0c52-42ae-a25d-3210569a2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet50 model without the final classification layer.\n",
    "# Global average pooling ensures we get a fixed-size embedding vector.\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "\n",
    "def extract_image_feature(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Uses a pre-trained ResNet50 to compute a robust embedding for the image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        target_size (tuple): Target size for resizing the image before feature extraction.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array representing the extracted image feature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Ensure image is in RGB\n",
    "            if img.mode != \"RGB\":\n",
    "                img = img.convert(\"RGB\")\n",
    "            # Resize image to target size (ResNet50 expects 224x224)\n",
    "            img = img.resize(target_size)\n",
    "            # Convert image to array and preprocess\n",
    "            x = keras_image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            # Extract features\n",
    "            features = base_model.predict(x)\n",
    "            return features.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return np.full(base_model.output_shape[1], np.nan)  # return a vector of NaNs\n",
    "\n",
    "\n",
    "def extract_metadata_feature(instance_name, metadata):\n",
    "    \"\"\"\n",
    "    Upgraded metadata feature extractor for generic datasets.\n",
    "    Uses simple heuristics to extract features from the metadata record.\n",
    "\n",
    "    For each key in the record (sorted for consistency):\n",
    "      - Numeric values are used directly.\n",
    "      - Strings are encoded via a simple hash (modulo operation, normalized to [0, 1]).\n",
    "      - Booleans are encoded as 1.0 or 0.0.\n",
    "      - Other types are ignored.\n",
    "\n",
    "    If no features are found, returns a single NaN.\n",
    "\n",
    "    Args:\n",
    "        instance_name (str): The key used to find the metadata record (assumed to be lower-cased).\n",
    "        metadata (dict): The metadata dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of extracted metadata features.\n",
    "    \"\"\"\n",
    "    record = metadata.get(instance_name.lower(), {})\n",
    "    features = []\n",
    "    for key in sorted(record.keys()):\n",
    "        value = record[key]\n",
    "        if isinstance(value, (int, float)):\n",
    "            features.append(float(value))\n",
    "        elif isinstance(value, bool):\n",
    "            features.append(1.0 if value else 0.0)\n",
    "        elif isinstance(value, str):\n",
    "            # Normalize a hash value of the string to [0, 1]\n",
    "            features.append((hash(value) % 1000) / 1000.0)\n",
    "        # Ignore other types for simplicity\n",
    "    if not features:\n",
    "        features = [np.nan]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb8a8a-3d5a-4965-a717-acd7e47fab60",
   "metadata": {},
   "source": [
    "### Extract Features for All Images\n",
    "\n",
    "**Image features**: Saved in `data/features/image_features.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166bd709-65d4-4a23-bace-81c19c5d4ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 809 images. Processing in 4 batches of up to 256 images each.\n",
      "Loading pre-trained ResNet50 model...\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step\n",
      "Batch 1/4 processed in 16.10 sec.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step\n",
      "Batch 2/4 processed in 14.80 sec.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step\n",
      "Batch 3/4 processed in 14.99 sec.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
      "Batch 4/4 processed in 3.62 sec.\n",
      "Extracted image features for 809 images in 49.73 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 14:54:33.248593: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image features to /app/data/features/image_features.npz\n"
     ]
    }
   ],
   "source": [
    "# Get image file names and paths\n",
    "image_files = [\n",
    "    f for f in os.listdir(IMAGE_DIR) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "]\n",
    "image_paths = [os.path.join(IMAGE_DIR, f) for f in image_files]\n",
    "# Preserve image names (without extension)\n",
    "image_names = [os.path.splitext(f)[0] for f in image_files]\n",
    "num_images = len(image_paths)\n",
    "batch_size = 256\n",
    "total_batches = int(np.ceil(num_images / batch_size))\n",
    "print(\n",
    "    f\"Found {num_images} images. Processing in {total_batches} batches of up to {batch_size} images each.\"\n",
    ")\n",
    "\n",
    "\n",
    "def process_image_with_name(file_path):\n",
    "    \"\"\"\n",
    "    Reads, decodes, resizes, and preprocesses an image.\n",
    "    Also extracts the file name from the path.\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    # Set the shape explicitly so that tf.image.resize works properly\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = preprocess_input(img)\n",
    "    # Extract filename from path (remove directory)\n",
    "    file_name = tf.strings.regex_replace(file_path, r\".*[\\\\/]\", \"\")\n",
    "    return img, file_name\n",
    "\n",
    "\n",
    "# Build the dataset using tf.data API\n",
    "ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "ds = ds.map(process_image_with_name, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds = ds.batch(batch_size)\n",
    "ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Load pre-trained ResNet50 model without the classification head.\n",
    "print(\"Loading pre-trained ResNet50 model...\")\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "all_image_features = {}\n",
    "batch_index = 0\n",
    "start_total = time.time()\n",
    "\n",
    "# Process images in batches\n",
    "for batch_imgs, batch_file_names in ds:\n",
    "    start_batch = time.time()\n",
    "    features_batch = base_model.predict(batch_imgs)\n",
    "    batch_time = time.time() - start_batch\n",
    "    # Convert file names tensor to numpy array of byte strings\n",
    "    batch_file_names = batch_file_names.numpy()\n",
    "    for i, file_name in enumerate(batch_file_names):\n",
    "        name = file_name.decode(\"utf-8\")\n",
    "        name = os.path.splitext(name)[0]\n",
    "        all_image_features[name] = features_batch[i]\n",
    "    batch_index += 1\n",
    "    print(f\"Batch {batch_index}/{total_batches} processed in {batch_time:.2f} sec.\")\n",
    "\n",
    "total_time = time.time() - start_total\n",
    "print(f\"Extracted image features for {num_images} images in {total_time:.2f} sec.\")\n",
    "\n",
    "# Reorder features to match original ordering\n",
    "image_feature_list = [all_image_features[name] for name in image_names]\n",
    "\n",
    "# Save image features as a compressed NumPy file (.npz)\n",
    "img_features_array = np.vstack(image_feature_list)\n",
    "img_features_path = FEATURE_DIR / \"image_features.npz\"\n",
    "np.savez_compressed(\n",
    "    img_features_path, image_names=image_names, features=img_features_array\n",
    ")\n",
    "print(f\"Saved image features to {img_features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9993c-ca37-4c1d-b1f4-6d95b24c58fe",
   "metadata": {},
   "source": [
    "# Metadata Feature Extraction Cell\n",
    "\n",
    "**Metadata features**: Saved in `features/features/metadata_features.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56921d11-619f-4592-89eb-7310723f7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum metadata feature length: 4\n",
      "Saved metadata features to /app/data/features/metadata_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Assume metadata is loaded from the JSON file\n",
    "import json\n",
    "\n",
    "with open(METADATA_PATH, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "\n",
    "# Assume extract_metadata_feature() is defined as follows:\n",
    "def extract_metadata_feature(instance_name, metadata):\n",
    "    \"\"\"\n",
    "    Upgraded metadata feature extractor for generic datasets.\n",
    "    Uses simple heuristics to extract features from the metadata record.\n",
    "\n",
    "    For each key in the record (sorted for consistency):\n",
    "      - Numeric values are used directly.\n",
    "      - Strings are encoded via a simple hash (modulo operation, normalized to [0, 1]).\n",
    "      - Booleans are encoded as 1.0 or 0.0.\n",
    "      - Other types are ignored.\n",
    "\n",
    "    If no features are found, returns a single NaN.\n",
    "\n",
    "    Args:\n",
    "        instance_name (str): The key used to find the metadata record (assumed lower-cased).\n",
    "        metadata (dict): The metadata dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of extracted metadata features.\n",
    "    \"\"\"\n",
    "    record = metadata.get(instance_name.lower(), {})\n",
    "    features = []\n",
    "    for key in sorted(record.keys()):\n",
    "        value = record[key]\n",
    "        if isinstance(value, (int, float)):\n",
    "            features.append(float(value))\n",
    "        elif isinstance(value, bool):\n",
    "            features.append(1.0 if value else 0.0)\n",
    "        elif isinstance(value, str):\n",
    "            # Normalize hash value to [0, 1]\n",
    "            features.append((hash(value) % 1000) / 1000.0)\n",
    "    if not features:\n",
    "        features = [np.nan]\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# --- Metadata Feature Extraction ---\n",
    "metadata_feature_list = []\n",
    "for name in image_names:\n",
    "    meta_feature = extract_metadata_feature(name, metadata)\n",
    "    metadata_feature_list.append(meta_feature)\n",
    "\n",
    "feature_lengths = [len(f) for f in metadata_feature_list]\n",
    "\n",
    "# Determine the maximum feature length and pad if necessary\n",
    "max_len = max(feature_lengths)\n",
    "print(f\"Maximum metadata feature length: {max_len}\")\n",
    "\n",
    "padded_metadata_features = [\n",
    "    np.pad(f, (0, max_len - len(f)), mode=\"constant\", constant_values=np.nan)\n",
    "    for f in metadata_feature_list\n",
    "]\n",
    "\n",
    "# Create a DataFrame and save as CSV\n",
    "df_meta = pd.DataFrame(np.vstack(padded_metadata_features), index=image_names)\n",
    "meta_features_path = FEATURE_DIR / \"metadata_features.csv\"\n",
    "df_meta.to_csv(meta_features_path)\n",
    "print(f\"Saved metadata features to {meta_features_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
