{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Define absolute paths\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "REPO_ROOT = NOTEBOOK_DIR.parent  # Go up one level from notebooks dir\n",
    "DATASET_PATH = REPO_ROOT / \"data\"\n",
    "IMAGE_DIR = DATASET_PATH / \"images\"\n",
    "METADATA_PATH = DATASET_PATH / \"metadata\" / \"pokemon_types.json\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METADATA_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /root/.cache/kagglehub/datasets/vishalsubbiah/pokemon-images-and-types/versions/4\n",
      "\n",
      "=== Paths ===\n",
      "Current working directory: /app/notebooks\n",
      "Repository root: /app\n",
      "Dataset path: /app/data\n",
      "Image directory: /app/data/images\n",
      "Metadata path: /app/data/metadata/pokemon_types.json\n"
     ]
    }
   ],
   "source": [
    "#%pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "kaggle_path = kagglehub.dataset_download(\"vishalsubbiah/pokemon-images-and-types\")\n",
    "print(\"Dataset downloaded to:\", kaggle_path)\n",
    "\n",
    "# The kaggle paths\n",
    "KAGGLE_IMAGES = Path(kaggle_path) / \"images\"\n",
    "KAGGLE_CSV = Path(kaggle_path) / \"pokemon.csv\"\n",
    "\n",
    "print(\"\\n=== Paths ===\")\n",
    "print(f\"Current working directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Image directory: {IMAGE_DIR}\")\n",
    "print(f\"Metadata path: {METADATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Data ===\n",
      "Loading CSV from: /root/.cache/kagglehub/datasets/vishalsubbiah/pokemon-images-and-types/versions/4/pokemon.csv\n",
      "Loading images from: /root/.cache/kagglehub/datasets/vishalsubbiah/pokemon-images-and-types/versions/4/images\n"
     ]
    }
   ],
   "source": [
    "# Define our paths\n",
    "# DATASET_PATH = \"data\"\n",
    "# IMAGE_DIR = os.path.join(DATASET_PATH, \"images\")\n",
    "# METADATA_PATH = os.path.join(DATASET_PATH, \"metadata\", \"pokemon_types.json\")\n",
    "\n",
    "# The kaggle paths (these are now under the downloaded path)\n",
    "KAGGLE_IMAGES = os.path.join(kaggle_path, \"images\")\n",
    "KAGGLE_CSV = os.path.join(kaggle_path, \"pokemon.csv\")\n",
    "\n",
    "print(\"\\n=== Loading Data ===\")\n",
    "print(f\"Loading CSV from: {KAGGLE_CSV}\")\n",
    "print(f\"Loading images from: {KAGGLE_IMAGES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 809 Pokemon from CSV\n",
      "Saved metadata to: /app/data/metadata/pokemon_types.json\n",
      "Copied 809 images to: /app/data/images\n"
     ]
    }
   ],
   "source": [
    "# Load and process the CSV data\n",
    "df = pd.read_csv(KAGGLE_CSV)\n",
    "print(f\"\\nLoaded {len(df)} Pokemon from CSV\")\n",
    "\n",
    "# Clean the data and create a JSON structure\n",
    "pokemon_data = {}\n",
    "for _, row in df.iterrows():\n",
    "    pokemon_data[row['Name'].lower()] = {\n",
    "        'name': row['Name'],\n",
    "        'type1': row['Type1'],\n",
    "        'type2': row['Type2'] if pd.notna(row['Type2']) else None,\n",
    "        'evolution': row['Evolution'] if pd.notna(row['Evolution']) else None\n",
    "    }\n",
    "\n",
    "# Save metadata as JSON\n",
    "os.makedirs(os.path.dirname(METADATA_PATH), exist_ok=True)\n",
    "with open(METADATA_PATH, 'w') as f:\n",
    "    json.dump(pokemon_data, f, indent=2)\n",
    "print(f\"Saved metadata to: {METADATA_PATH}\")\n",
    "\n",
    "# Copy images to our data directory\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "image_count = 0\n",
    "for img_file in os.listdir(KAGGLE_IMAGES):\n",
    "    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        src = os.path.join(KAGGLE_IMAGES, img_file)\n",
    "        dst = os.path.join(IMAGE_DIR, img_file.lower())\n",
    "        shutil.copy2(src, dst)\n",
    "        image_count += 1\n",
    "print(f\"Copied {image_count} images to: {IMAGE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Dataset Validation ===\")\n",
    "\n",
    "# Check images\n",
    "image_files = [f.lower() for f in os.listdir(IMAGE_DIR) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(f\"\\nFound {len(image_files)} images\")\n",
    "\n",
    "# Check metadata\n",
    "with open(METADATA_PATH) as f:\n",
    "    metadata = json.load(f)\n",
    "print(f\"Found {len(metadata)} pokemon in metadata\")\n",
    "\n",
    "# Cross-reference\n",
    "images_without_metadata = []\n",
    "metadata_without_images = []\n",
    "\n",
    "# Check for images without metadata\n",
    "for img_file in image_files:\n",
    "    pokemon_name = os.path.splitext(img_file)[0].lower()\n",
    "    if pokemon_name not in metadata:\n",
    "        images_without_metadata.append(img_file)\n",
    "\n",
    "# Check for metadata without images\n",
    "for pokemon_name in metadata:\n",
    "    if not any(pokemon_name in img_file for img_file in image_files):\n",
    "        metadata_without_images.append(pokemon_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image statistics\n",
    "print(\"\\n=== Image Statistics ===\")\n",
    "sizes = []\n",
    "formats = set()\n",
    "corrupt_images = []\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            sizes.append(img.size)\n",
    "            formats.add(img.format)\n",
    "    except Exception as e:\n",
    "        corrupt_images.append((img_file, str(e)))\n",
    "\n",
    "unique_sizes = set(sizes)\n",
    "print(f\"\\nFound {len(unique_sizes)} different image sizes:\")\n",
    "for size in list(unique_sizes)[:5]:\n",
    "    count = sizes.count(size)\n",
    "    print(f\"- {size}: {count} images\")\n",
    "if len(unique_sizes) > 5:\n",
    "    print(\"...\")\n",
    "\n",
    "print(f\"\\nImage formats: {', '.join(formats)}\")\n",
    "\n",
    "if corrupt_images:\n",
    "    print(\"\\n=== Corrupt Images ===\")\n",
    "    print(f\"Found {len(corrupt_images)} corrupt images:\")\n",
    "    for img, error in corrupt_images[:5]:\n",
    "        print(f\"- {img}: {error}\")\n",
    "    if len(corrupt_images) > 5:\n",
    "        print(\"...\")\n",
    "\n",
    "# Type statistics\n",
    "print(\"\\n=== Type Statistics ===\")\n",
    "primary_types = df['Type1'].value_counts()\n",
    "secondary_types = df['Type2'].value_counts()\n",
    "\n",
    "print(\"\\nPrimary Types:\")\n",
    "for type_name, count in primary_types.items():\n",
    "    print(f\"- {type_name}: {count}\")\n",
    "\n",
    "print(\"\\nSecondary Types:\")\n",
    "for type_name, count in secondary_types.items():\n",
    "    if pd.notna(type_name):\n",
    "        print(f\"- {type_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
